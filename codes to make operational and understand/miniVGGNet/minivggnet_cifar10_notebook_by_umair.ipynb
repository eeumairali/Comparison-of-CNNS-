{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. setting matplotliba and importing all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "#We need to set the matplotlib backend to Agg to indicate to create a non-interactive that will simply be saved to disk\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from dhruv.nn.conv import minivggnet\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tensorflow.keras.layers import BatchNormalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. writing path for output and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] loading CIFAR-10 data...\n"
     ]
    }
   ],
   "source": [
    "args = {}\n",
    "args[\"output\"] = \"output\"\n",
    "\n",
    "\n",
    "print(\"[Info] loading CIFAR-10 data...\")\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "testX = testX.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. label dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.fit_transform(testY)\n",
    "\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. compiling Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] compiling network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umair-ali/Desktop/phd deep learning after mid/codes to make operational and understand/tf_phd/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "/home/umair-ali/Desktop/phd deep learning after mid/codes to make operational and understand/tf_phd/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"[Info] compiling network...\")\n",
    "opt = SGD(learning_rate=0.01, decay=0.01 / 40, momentum=0.9, nesterov=True)\n",
    "model = minivggnet.MiniVGGNet.build(width=32, height=32, depth=3, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=opt, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. traingin network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] training network...\n",
      "Epoch 1/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.3760 - loss: 1.9810 - val_accuracy: 0.5692 - val_loss: 1.2586\n",
      "Epoch 2/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5831 - loss: 1.2144 - val_accuracy: 0.6288 - val_loss: 1.0676\n",
      "Epoch 3/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6436 - loss: 1.0259 - val_accuracy: 0.6668 - val_loss: 0.9911\n",
      "Epoch 4/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6940 - loss: 0.8734 - val_accuracy: 0.7248 - val_loss: 0.7890\n",
      "Epoch 5/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7216 - loss: 0.7958 - val_accuracy: 0.7436 - val_loss: 0.7466\n",
      "Epoch 6/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7448 - loss: 0.7289 - val_accuracy: 0.7260 - val_loss: 0.7703\n",
      "Epoch 7/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7589 - loss: 0.6798 - val_accuracy: 0.7682 - val_loss: 0.6749\n",
      "Epoch 8/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7786 - loss: 0.6286 - val_accuracy: 0.7775 - val_loss: 0.6547\n",
      "Epoch 9/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7951 - loss: 0.5798 - val_accuracy: 0.7709 - val_loss: 0.6775\n",
      "Epoch 10/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 0.5477 - val_accuracy: 0.7754 - val_loss: 0.6735\n",
      "Epoch 11/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8196 - loss: 0.5062 - val_accuracy: 0.7934 - val_loss: 0.6028\n",
      "Epoch 12/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.4877 - val_accuracy: 0.7987 - val_loss: 0.5875\n",
      "Epoch 13/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8385 - loss: 0.4538 - val_accuracy: 0.7913 - val_loss: 0.6153\n",
      "Epoch 14/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8473 - loss: 0.4339 - val_accuracy: 0.8039 - val_loss: 0.5723\n",
      "Epoch 15/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8587 - loss: 0.3982 - val_accuracy: 0.8028 - val_loss: 0.6116\n",
      "Epoch 16/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8639 - loss: 0.3837 - val_accuracy: 0.8111 - val_loss: 0.5817\n",
      "Epoch 17/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8709 - loss: 0.3626 - val_accuracy: 0.8072 - val_loss: 0.5804\n",
      "Epoch 18/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8775 - loss: 0.3446 - val_accuracy: 0.8040 - val_loss: 0.6062\n",
      "Epoch 19/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8845 - loss: 0.3253 - val_accuracy: 0.7889 - val_loss: 0.6374\n",
      "Epoch 20/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8875 - loss: 0.3148 - val_accuracy: 0.8124 - val_loss: 0.5835\n",
      "Epoch 21/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.3026 - val_accuracy: 0.8112 - val_loss: 0.5961\n",
      "Epoch 22/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8962 - loss: 0.2878 - val_accuracy: 0.8226 - val_loss: 0.5579\n",
      "Epoch 23/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9027 - loss: 0.2706 - val_accuracy: 0.8161 - val_loss: 0.5955\n",
      "Epoch 24/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9027 - loss: 0.2710 - val_accuracy: 0.8212 - val_loss: 0.5739\n",
      "Epoch 25/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9076 - loss: 0.2531 - val_accuracy: 0.8268 - val_loss: 0.5734\n",
      "Epoch 26/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9141 - loss: 0.2436 - val_accuracy: 0.8170 - val_loss: 0.5795\n",
      "Epoch 27/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9124 - loss: 0.2445 - val_accuracy: 0.8170 - val_loss: 0.5957\n",
      "Epoch 28/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.2285 - val_accuracy: 0.8078 - val_loss: 0.6232\n",
      "Epoch 29/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.2243 - val_accuracy: 0.8067 - val_loss: 0.6499\n",
      "Epoch 30/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9188 - loss: 0.2247 - val_accuracy: 0.8203 - val_loss: 0.6013\n",
      "Epoch 31/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9249 - loss: 0.2121 - val_accuracy: 0.8191 - val_loss: 0.6159\n",
      "Epoch 32/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9304 - loss: 0.1975 - val_accuracy: 0.8274 - val_loss: 0.5884\n",
      "Epoch 33/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9324 - loss: 0.1953 - val_accuracy: 0.8247 - val_loss: 0.6151\n",
      "Epoch 34/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9308 - loss: 0.1953 - val_accuracy: 0.8200 - val_loss: 0.6233\n",
      "Epoch 35/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9333 - loss: 0.1926 - val_accuracy: 0.8263 - val_loss: 0.6461\n",
      "Epoch 36/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 0.1782 - val_accuracy: 0.8279 - val_loss: 0.5823\n",
      "Epoch 37/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9378 - loss: 0.1759 - val_accuracy: 0.8176 - val_loss: 0.6395\n",
      "Epoch 38/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.1653 - val_accuracy: 0.8285 - val_loss: 0.6026\n",
      "Epoch 39/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9382 - loss: 0.1752 - val_accuracy: 0.8277 - val_loss: 0.5991\n",
      "Epoch 40/40\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.1592 - val_accuracy: 0.8258 - val_loss: 0.6255\n"
     ]
    }
   ],
   "source": [
    "print(\"[Info] training network...\")\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=epoch_size, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] evaluating network...\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.85      0.84      0.84      1000\n",
      "  automobile       0.92      0.90      0.91      1000\n",
      "        bird       0.79      0.70      0.74      1000\n",
      "         cat       0.72      0.62      0.67      1000\n",
      "        deer       0.78      0.84      0.81      1000\n",
      "         dog       0.71      0.79      0.75      1000\n",
      "        frog       0.86      0.87      0.87      1000\n",
      "       horse       0.84      0.89      0.87      1000\n",
      "        ship       0.89      0.92      0.90      1000\n",
      "       truck       0.88      0.89      0.89      1000\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.82     10000\n",
      "weighted avg       0.83      0.83      0.82     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[Info] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=64)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epoch_size), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, epoch_size), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, epoch_size), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, epoch_size), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on CIFAR-10\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(args[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
